---
title: "exp1"
format: html
editor: visual
---

### Load packages

```{r}
# List of packages
packages <- c("corrr", "ggplot2", "lme4", "lmerTest", "FactoMineR", "grid","png","cowplot","magick", "ggimage","dplyr","tidyverse","knitr")


```

```{r}

install_and_load_packages <- function(packages) {
  for(package in packages) {
    if(!require(package, character.only = TRUE)) {
      install.packages(package, dependencies = TRUE)
      library(package, character.only = TRUE)
    }
  }
}

# Call the function with the list of packages
install_and_load_packages(packages)

```

```{r}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

```

## Set working directories

```{r}
current_dir<- getwd()

data_dir <-paste0(current_dir,'/../data/')
data_files <-list.files(path = data_dir, full.names = TRUE, pattern="*.csv")
print(paste0('we have data from ',length(data_files),' participants'))



```

## Load in data and filter our texture ids

```{r}

df_list <- lapply(data_files, read.csv)

experiment_data_raw<- bind_rows(df_list)
ratings_trials<- experiment_data_raw %>% filter(trial_type== 'html-slider-response')
ratings_trials_exp<- ratings_trials %>% filter(practiceTrial != 'true')

ratings_trials_exp$response<- as.numeric(ratings_trials_exp$response)
ratings_trials_exp$response<- (ratings_trials_exp$response + 200)/400



extract_texture_id<-function(filename){
  f<- str_split_i(filename,"/",2)
  f<- str_split_i(f,".png",1)
  return(f)
  
}

ratings_trials_exp$texture <- lapply(ratings_trials_exp$texture_id,extract_texture_id)


unique_sona_ids <- unique(ratings_trials_exp$sona_id)
cat(paste(unique_sona_ids, collapse = ", "))
```

```{r}
t<-ratings_trials_exp %>%
  group_by(condition_num) %>%
  summarise(unique_subjects = n_distinct(subject_id))

concept_groups <- ratings_trials_exp %>% 
  select(concept, condition_num) %>% 
  distinct() %>% 
  arrange(condition_num)
```
```{r}
colnames(t) <- c("condition_num", "unique_subjects")
t2 <- as.data.frame(t)

```

## Group and pivot into a concept x texture matrix

```{r}
ratings_trial_grouped <- ratings_trials_exp %>% group_by(texture, concept) %>%summarise(mean_rating = mean(response)) 


ratings_trials_grouped_wide<-ratings_trial_grouped %>%
  pivot_wider(names_from = texture, values_from = mean_rating)

ratings_trials_grouped_wide
```

```{r}
### compute matrix rank
SVD <- svd(ratings_trials_grouped_wide[,2:ncol(ratings_trials_grouped_wide)])$d > 1e-10
mat_rank <- sum(SVD)
print(mat_rank)
```


```{r}

bootstrap_associations_matrices<- function(ratings_df, sample_size){
  
  group1ids<- ratings_df %>%
  group_by(condition_num) %>%
  sample_n(sample_size,replace = TRUE)%>%select(subject_id)
  
  group2ids <- ratings_df %>%
  # filter(!subject_id %in% group1ids$subject_id) %>%
  group_by(condition_num) %>%
  sample_n(sample_size, replace = TRUE) %>%
  select(subject_id)
  
  group1df<-ratings_df%>%filter(subject_id%in%group1ids$subject_id)
  group2df<-ratings_df%>%filter(subject_id%in%group2ids$subject_id)
  
  group1mat<- group1df%>% group_by(texture, concept) %>%summarise(mean_rating = mean(response),.groups='keep')%>%
  pivot_wider(names_from = texture, values_from = mean_rating)
  group2mat<- group2df%>% group_by(texture, concept) %>%summarise(mean_rating = mean(response),.groups='keep')%>%
  pivot_wider(names_from = texture, values_from = mean_rating)
  
  concept_names <- group1mat$concept # Preserve concept names in correct order for later
  
  group1mat <- group1mat[order(group1mat$concept), -1]  # Remove concept column
  group2mat <- group2mat[order(group2mat$concept), -1]  # Remove concept column
  
  common_columns <- intersect(colnames(group1mat), colnames(group2mat))  # Find common columns
  group1mat <- group1mat[, sort(common_columns)]
  group2mat <- group2mat[, sort(common_columns)]
  
  ### @Anna lol could you just change things below so that we compute concept-wise correlations and return a dataframe of correlations for each concept
  
  ### @Kushin lol yes. I changed things so that the function returns a list with both the mean_correlation and the correlation_df (the correlation_df specifies the correlation value for each concept)
  
  rowwise_correlations <- mapply(function(row1, row2) {
    cor(row1, row2, use = "pairwise.complete.obs")
  }, as.data.frame(t(group1mat)), as.data.frame(t(group2mat)))
  
  # Create dataframe of concept-wise correlations
  correlation_df <- data.frame(
    concept = concept_names,
    correlation = rowwise_correlations
  )
  
  # Compute mean correlation
  mean_correlation <- mean(rowwise_correlations, na.rm = TRUE)
  
  return(list(mean_correlation = mean_correlation, correlation_df = correlation_df))

  
}


```

```{r}
### @Kushin I updated the running code so that it works as before with the updated function 
iters<-numeric()
sample_sizes<-numeric()
mean_rs<-numeric()
correlation_dfs<-list()
for(iter in 1:1000){
for(sample_size in seq(5, 80, by = 5)){
  result <- bootstrap_associations_matrices(ratings_trials_exp, sample_size)
  mean_rs <- rbind(mean_rs, result$mean_correlation)
  correlation_dfs[[length(correlation_dfs) + 1]] <- result$correlation_df
  iters<- rbind(iters, iter)
  sample_sizes<-rbind(sample_sizes, sample_size)

}
}


bootstrap_df <- data.frame(cbind( iters,sample_sizes,mean_rs
))
colnames(bootstrap_df)<- c('iteration','sample_size','mean_reliability')



# Summarize data to calculate mean and standard error for each sample_size
summary_results <-bootstrap_df %>%
    group_by(sample_size) %>%
    summarise(
        se_reliability = sd(mean_reliability, na.rm = TRUE) / sqrt(n()),
        mean_reliability = mean(mean_reliability, na.rm = TRUE),
       
    )

# Create ggplot - this is for overall data - not seperated by group and concept
ggplot(summary_results, aes(x = sample_size, y = mean_reliability)) +
  geom_line(color = "blue") +
  geom_ribbon(aes(ymin = mean_reliability - se_reliability,
                  ymax = mean_reliability + se_reliability),
              alpha = 0.1, fill = "red") +
  labs(
    title = "Mean Reliability Across Sample Sizes",
    x = "Sample Size",
    y = "Mean Reliability"
  ) +
  theme_minimal()
```

```{r}
# Now plots for individual concepts

# Combine all correlation data frames into one with iteration and sample size info
correlation_summary_df <- bind_rows(
  lapply(seq_along(correlation_dfs), function(i) {
    cbind(
      iteration = iters[i],
      sample_size = sample_sizes[i],
      correlation_dfs[[i]]
    )
  })
)

# Summarize data for each concept and sample size
summary_correlation_results <- correlation_summary_df %>%
  group_by(concept, sample_size) %>%
  summarise(
    mean_correlation = mean(correlation, na.rm = TRUE),
    se_correlation = sd(correlation, na.rm = TRUE) / sqrt(n()),
    .groups = "drop"
  )

# Add condition_num
summary_correlation_results <- left_join(summary_correlation_results, concept_groups, by = "concept") %>% 
  arrange(condition_num)


#ggplot
ggplot(summary_correlation_results, aes(x = sample_size, y = mean_correlation, color = concept)) +
  geom_line() +
  geom_ribbon(aes(ymin = mean_correlation - se_correlation, ymax = mean_correlation + se_correlation, group = concept),
              alpha = 0.1, fill = "red", color = NA) +
  geom_text(
    data = summary_correlation_results %>%
      group_by(condition_num, concept) %>%
      filter(sample_size == max(sample_size)), # Place label at the largest sample size
    aes(
      x = sample_size,
      y = mean_correlation,
      label = concept
    ),
    hjust = -0.1, # Slightly offset the labels horizontally
    vjust = 0, # Adjust vertical spacing
    size = 3,
    inherit.aes = FALSE # Avoid inheriting other plot aesthetics
  ) +
  # Add vertical lines for current sample sizes from `t2`
  geom_vline(
    data = t2,
    aes(xintercept = unique_subjects/2), 
    linetype = "dashed", 
    color = "black"
  ) +
  labs(
    title = "Mean Reliability Across Sample Sizes for Each Concept and Condition",
    x = "Sample Size",
    y = "Mean Reliability"
  ) +
  theme_minimal() +
  facet_wrap(~ condition_num, ncol = 7) + 
  theme(
    legend.position = "none",
    plot.margin = margin(50, 50, 50, 50),
    panel.spacing = unit(3, "lines")) +
  #scale_color_manual(values = custom_colors) +
  coord_cartesian(clip = "off")
```

```{r}
#split half correlations for current sample size
compute_correlations <- function(ratings_df, t2, condition_nums, n_iterations = 1000) {
  all_correlation_results <- vector("list", length(condition_nums) * n_iterations)
  counter <- 1  # To track the list index
  
  for (condition in condition_nums) {
    for (i in 1:n_iterations) {
      # Randomly split subjects into two groups
      group1ids <- ratings_df %>%
        filter(condition_num == condition) %>%
        sample_n(t2 %>% filter(condition_num == condition) %>% pull(unique_subjects) / 2, replace = FALSE) %>%
        select(subject_id)
      
      group2ids <- ratings_df %>%
        filter(condition_num == condition) %>%
        filter(!subject_id %in% group1ids$subject_id) %>%
        sample_n(t2 %>% filter(condition_num == condition) %>% pull(unique_subjects) / 2, replace = FALSE) %>%
        select(subject_id)
      
      # Create data matrices for both groups
      group1df <- ratings_df %>% filter(subject_id %in% group1ids$subject_id)
      group2df <- ratings_df %>% filter(subject_id %in% group2ids$subject_id)
      
      group1mat <- group1df %>%
        group_by(texture, concept) %>%
        summarise(mean_rating = mean(response), .groups = 'keep') %>%
        pivot_wider(names_from = texture, values_from = mean_rating)
      
      group2mat <- group2df %>%
        group_by(texture, concept) %>%
        summarise(mean_rating = mean(response), .groups = 'keep') %>%
        pivot_wider(names_from = texture, values_from = mean_rating)
      
      # Align matrices
      concept_names <- group1mat$concept
      group1mat <- group1mat[order(group1mat$concept), -1]  # Remove concept column
      group2mat <- group2mat[order(group2mat$concept), -1]  # Remove concept column
      
      common_columns <- intersect(colnames(group1mat), colnames(group2mat))
      group1mat <- group1mat[, sort(common_columns)]
      group2mat <- group2mat[, sort(common_columns)]
      
      # Compute correlations
      rowwise_correlations <- mapply(
        function(row1, row2) cor(row1, row2, use = "pairwise.complete.obs"),
        as.data.frame(t(group1mat)), as.data.frame(t(group2mat))
      )
      
      # Store results
      all_correlation_results[[counter]] <- data.frame(
        iteration = i,
        condition_num = condition,
        concept = concept_names,
        correlation = rowwise_correlations
      )
      
      counter <- counter + 1  # Increment index
    }
  }
  
  # Combine all results into a single data frame
  return(bind_rows(all_correlation_results))
}

# Get unique condition numbers from ratings_df
condition_nums <- unique(ratings_trials_exp$condition_num)

# Run the function
all_results <- compute_correlations(ratings_trials_exp, t2, condition_nums, n_iterations = 1000)
```

```{r}
#plot distributions of correlations for each concept in each group
```

```{r}
#plotting

#combine correlation_summary_df with all_results for combined plotting
#first make all_results smaller for r's memory
all_results <- all_results %>% 
  group_by(condition_num, concept) %>% 
  mutate(
    avg_correlation = mean(correlation)
  ) %>% 
  ungroup()

all_results <- all_results %>% 
  select(condition_num, concept, avg_correlation) %>% 
  ungroup()
  
all_results <- all_results %>% 
  distinct()

boostrapping_w_split_half <- merge(summary_correlation_results, all_results, by = "concept", all.x = TRUE)

boostrapping_w_split_half <- boostrapping_w_split_half %>% 
  select(-condition_num.y) %>% 
  rename(condition_num = condition_num.x)

#add t2 for unique_subjects
boostrapping_w_split_half <- left_join(boostrapping_w_split_half, t2, by = "condition_num")

#make sure condition_num is character value 
boostrapping_w_split_half <- boostrapping_w_split_half %>% 
  mutate(
    condition_num = as.character(condition_num)
  )

#use summary results from boostrapping to compare
#create vertical line each group at current sample size
#add point for correlation for each group at current sample size

#ggplot
ggplot(boostrapping_w_split_half, aes(x = sample_size, y = mean_correlation, color = concept)) +
  geom_line() +
  geom_ribbon(aes(ymin = mean_correlation - se_correlation, ymax = mean_correlation + se_correlation, group = concept),
              alpha = 0.1, fill = "red", color = NA) +
  geom_text(
    data = boostrapping_w_split_half %>%
      group_by(condition_num, concept) %>%
      filter(sample_size == max(sample_size)), # Place label at the largest sample size
    aes(
      x = sample_size,
      y = mean_correlation,
      label = concept
    ),
    hjust = -0.1, # Slightly offset the labels horizontally
    vjust = 0, # Adjust vertical spacing
    size = 3,
    inherit.aes = FALSE # Avoid inheriting other plot aesthetics
  ) +
  # Add vertical lines for current sample sizes from `t2`
  geom_vline(
    data = boostrapping_w_split_half,
    aes(xintercept = unique_subjects/2), 
    linetype = "dashed", 
    color = "black"
  ) +
  geom_point(
    data = boostrapping_w_split_half,
    aes(x = unique_subjects/2, y = avg_correlation, color = concept, group = concept)
  ) +
  labs(
    title = "Mean Reliability Across Sample Sizes for Each Concept and Condition",
    x = "Sample Size",
    y = "Mean Reliability"
  ) +
  theme_minimal() +
  facet_wrap(~ condition_num, ncol = 7) + 
  theme(
    legend.position = "none",
    plot.margin = margin(50, 50, 50, 50),
    panel.spacing = unit(3, "lines")) +
  #scale_color_manual(values = custom_colors) +
  coord_cartesian(clip = "off")

```
